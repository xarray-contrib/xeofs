{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Geographically weighted PCA\n",
    "Geographically Weighted Principal Component Analysis (GWPCA) is a spatial analysis method that identifies and visualizes local spatial patterns and relationships in multivariate datasets across various geographic areas. It operates by applying PCA within a moving window over a geographical region, which enables the extraction of local principal components that can differ across locations.\n",
    "\n",
    "TIn this demonstration, we'll apply GWPCA to a dataset detailing the chemical compositions of soils from countries around the Baltic Sea [1]_. This example is inspired by a tutorial originally crafted and published by Chris Brunsdon [2]_.\n",
    "The dataset comprises 10 variables (chemical elements) and spans 768 samples.\n",
    "Here, each sample refers to a pair of latitude and longitude coordinates, representing specific sampling stations.\n",
    "\n",
    ".. [1] Reimann, C. et al. Baltic soil survey: total concentrations of major and selected trace elements in arable soils from 10 countries around the Baltic Sea. Science of The Total Environment 257, 155â€“170 (2000).\n",
    ".. [2] https://rpubs.com/chrisbrunsdon/99675\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>The dataset we're using is found in the R package\n",
    "    [mvoutlier](https://cran.r-project.org/web/packages/mvoutlier/mvoutlier.pdf).\n",
    "    To access it, we'll employ the Python package\n",
    "    [rpy2](https://rpy2.github.io/doc/latest/html/index.html) which facilitates\n",
    "    interaction with R packages from within Python.</p></div>\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Presently, there's no support for ``xarray.Dataset`` lacking an explicit feature dimension.\n",
    "    As a workaround, ``xarray.DataArray.to_array`` can be used to convert the ``Dataset`` to an ``DataArray``.</p></div>\n",
    "\n",
    "<div class=\"alert alert-danger\"><h4>Warning</h4><p>Bear in mind that GWPCA requires significant computational power.\n",
    "    The ``xeofs`` implementation is optimized for CPU efficiency and is best suited\n",
    "    for smaller to medium data sets. For more extensive datasets where parallel processing becomes essential,\n",
    "    it's advisable to turn to the R package [GWmodel](https://cran.r-project.org/web/packages/GWmodel/GWmodel.pdf).\n",
    "    This package harnesses CUDA to enable GPU-accelerated GWPCA for optimized performance.</p></div>\n",
    "\n",
    "\n",
    "Let's import the necessary packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the analysis\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xeofs as xe\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For accessing R packages\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll install the R package [mvoutlier](https://cran.r-project.org/web/packages/mvoutlier/mvoutlier.pdf)\n",
    "using the [rpy2](https://rpy2.github.io/doc/latest/html/index.html) package.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.set_options(display_expand_data=False)\n",
    "utils = importr(\"utils\")\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "utils.install_packages(\"mvoutlier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset and convert it into a ``pandas.DataFrame``.\n",
    "Alongside, we'll also load the background data that outlines the borders of countries\n",
    "in the Baltic Sea region. This will help us visually represent the GWPCA results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro.r(\n",
    "    \"\"\"\n",
    "    require(\"mvoutlier\")\n",
    "    data(bsstop)\n",
    "    Data <- bsstop[,1:14]\n",
    "    background <- bss.background\n",
    "    \"\"\"\n",
    ")\n",
    "with (ro.default_converter + pandas2ri.converter).context():\n",
    "    data_df = ro.conversion.get_conversion().rpy2py(ro.r[\"Data\"])\n",
    "    background_df = ro.conversion.get_conversion().rpy2py(ro.r[\"background\"])\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ``xeofs`` uses ``xarray``, we convert the data into an ``xarray.DataArray``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.rename(columns={\"ID\": \"station\"}).set_index(\"station\")\n",
    "data = data_df.to_xarray()\n",
    "data = data.rename({\"XCOO\": \"x\", \"YCOO\": \"y\"})\n",
    "data = data.set_index(station=(\"x\", \"y\"))\n",
    "data = data.drop_vars(\"CNo\")\n",
    "da = data.to_array(dim=\"element\")\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dive into the GWPCA. First, initialize a ``GWPCA`` instance and fit it to the data.\n",
    "The ``station`` dimension serves as our sample dimension, along which the local PCAs will be applied.\n",
    "Since these PCAs need to gauge distances to adjacent stations, we must specify\n",
    "a distance metric. Our station data includes coordinates in meters, so we'll\n",
    "choose the ``euclidean`` metric. If you have coordinates in degrees (like\n",
    "latitude and longitude), choose the ``haversine`` metric instead.\n",
    "We're also using a ``bisquare`` kernel with a bandwidth of 1000 km. Note that the\n",
    "bandwidth unit always follows input data (which is in meters here),\n",
    "except when using the ``haversine`` metric, which always gives distances in\n",
    "kilometers. Lastly, we'll standardize the input to ensure consistent scales\n",
    "for the chemical elements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwpca = xe.models.GWPCA(\n",
    "    n_modes=5,\n",
    "    standardize=True,\n",
    "    metric=\"euclidean\",\n",
    "    kernel=\"bisquare\",\n",
    "    bandwidth=1000000.0,\n",
    ")\n",
    "gwpca.fit(da, \"station\")\n",
    "gwpca.components()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``components`` method returns the local principal components for each station. Note that the\n",
    "dimensionality of the returned array is ``[station, element, mode]``, so in practice we don't really have\n",
    "reduced the dimensionality of the data set. However, we can\n",
    "extract the largest locally weighted components for each station which tells us which chemical elements\n",
    "dominate the local PCAs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llwc = gwpca.largest_locally_weighted_components()\n",
    "llwc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the spatial patterns of the chemical elements.\n",
    "As the stations are positioned on a irregular grid, we'll transform the\n",
    "``llwc`` ``DataArray`` into a ``pandas.DataFrame``. After that, we can easily visualize\n",
    "it using the ``scatter`` method.\n",
    "For demonstation, we'll concentrate on the first mode:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llwc1_df = llwc.sel(mode=1).to_dataframe()\n",
    "\n",
    "elements = da.element.values\n",
    "n_elements = len(elements)\n",
    "colors = np.arange(n_elements)\n",
    "col_dict = {el: col for el, col in zip(elements, colors)}\n",
    "\n",
    "llwc1_df[\"colors\"] = llwc1_df[\"largest_locally_weighted_components\"].map(col_dict)\n",
    "cmap = sns.color_palette(\"tab10\", n_colors=n_elements, as_cmap=True)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "background_df.plot.scatter(ax=ax, x=\"V1\", y=\"V2\", color=\".3\", marker=\".\", s=1)\n",
    "s = ax.scatter(\n",
    "    x=llwc1_df[\"x\"],\n",
    "    y=llwc1_df[\"y\"],\n",
    "    c=llwc1_df[\"colors\"],\n",
    "    ec=\"w\",\n",
    "    s=40,\n",
    "    cmap=cmap,\n",
    "    vmin=-0.5,\n",
    "    vmax=n_elements - 0.5,\n",
    ")\n",
    "cbar = fig.colorbar(mappable=s, ax=ax, label=\"Largest locally weighted component\")\n",
    "cbar.set_ticks(colors)\n",
    "cbar.set_ticklabels(elements)\n",
    "ax.set_title(\"Largest locally weighted element\", loc=\"left\", weight=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step, let's examine the explained variance. Like standard PCA,\n",
    "this gives us insight into the variance explained by each mode. But with a\n",
    "local PCA for every station, the explained variance varies spatially. Notably,\n",
    "the first mode's explained variance differs across countries, ranging from\n",
    "roughly 40% to 70%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_var_ratio = gwpca.explained_variance_ratio()\n",
    "evr1_df = exp_var_ratio.sel(mode=1).to_dataframe()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "background_df.plot.scatter(ax=ax, x=\"V1\", y=\"V2\", color=\".3\", marker=\".\", s=1)\n",
    "evr1_df.plot.scatter(\n",
    "    ax=ax, x=\"x\", y=\"y\", c=\"explained_variance_ratio\", vmin=0.4, vmax=0.7\n",
    ")\n",
    "ax.set_title(\"Fraction of locally explained variance\", loc=\"left\", weight=800)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
